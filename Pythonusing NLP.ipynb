{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPb7hS4LDRPV7j/v2mQDZ7U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyperprizma/PythonLab/blob/main/Pythonusing%20NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Demonstrate the working of pre processing stages of NLP such as stemming, lemmatization in NPL.\n",
        "\n",
        "#First we need to import the stemming modules\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "ps = PorterStemmer()\n",
        "#Now we will choose the word which need to be stemmed\n",
        "words = (\"program\", \"programs\", \"programmer\", \"programming\", \"programmers\")\n",
        "for w in words:\n",
        "  print(w, \":\", ps.stem(w))\n"
      ],
      "metadata": {
        "id": "TZc3DD-c-c7g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb2ea15-4738-4716-e58e-4476c567e88a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "program : program\n",
            "programs : program\n",
            "programmer : programm\n",
            "programming : program\n",
            "programmers : programm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmatization in NLP\n",
        "#First import these modules\n",
        "from nltk.stem import WordNetLemmatizer\n",
        " \n",
        "lemmatizer = WordNetLemmatizer()\n",
        " \n",
        "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
        "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
        " \n",
        "# a denotes adjective in \"pos\"\n",
        "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))"
      ],
      "metadata": {
        "id": "oP7aC2UvA18X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demonstrate the working of confusion matrix and other related terms like precision, recall etc.\n",
        "#Ans)The precision is the proportion of relevant results in the list of all returned search results. \n",
        "#Ans)The recall is the ratio of the relevant results returned by the search engine to the total number of the relevant results that could have been returned.\n",
        "#First Importing the dependancies\n",
        "from sklearn import metrics\n",
        "# Predicted values\n",
        "y_pred = [\"a\", \"b\", \"c\", \"a\", \"b\"]\n",
        "# Actual values\n",
        "y_act = [\"a\", \"b\", \"c\", \"c\", \"a\"]\n",
        "# Printing the confusion matrix\n",
        "# The columns will show the instances predicted for each label,\n",
        "# and the rows will show the actual number of instances for each label.\n",
        "print(metrics.confusion_matrix(y_act, y_pred, labels=[\"a\", \"b\", \"c\"]))\n",
        "# Printing the precision and recall, among other metrics\n",
        "print(metrics.classification_report(y_act, y_pred, labels=[\"a\", \n",
        "\"b\",\"c\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2XETj_iJ7Qh",
        "outputId": "9a64ab0c-c457-4a77-c34d-2538ebabfbcf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 0]\n",
            " [0 1 0]\n",
            " [1 0 1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           a       0.50      0.50      0.50         2\n",
            "           b       0.50      1.00      0.67         1\n",
            "           c       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.60         5\n",
            "   macro avg       0.67      0.67      0.61         5\n",
            "weighted avg       0.70      0.60      0.60         5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Demonstrate the working of \"term frequency-inverse document frequency\"\n",
        "# import required module\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# assign documents\n",
        "d0 = 'Geeks for geeks'\n",
        "d1 = 'Geeks'\n",
        "d2 = 'r2j'\n",
        "\n",
        "# merge documents into a single corpus\n",
        "string = [d0, d1, d2]\n",
        "\n",
        "# create object\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "# get tf-df values\n",
        "result = tfidf.fit_transform(string)\n",
        "\n",
        "# get idf values\n",
        "print('\\nidf values:')\n",
        "for ele1, ele2 in zip(tfidf.get_feature_names(), tfidf.idf_):\n",
        "\tprint(ele1, ':', ele2)\n",
        "\n",
        "# get indexing\n",
        "print('\\nWord indexes:')\n",
        "print(tfidf.vocabulary_)\n",
        "\n",
        "# display tf-idf values\n",
        "print('\\ntf-idf value:')\n",
        "print(result)\n",
        "\n",
        "# in matrix form\n",
        "print('\\ntf-idf values in matrix form:')\n",
        "print(result.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWl69RM3LUGM",
        "outputId": "7d4df370-8217-48f5-c739-c833f0e633b1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "idf values:\n",
            "for : 1.6931471805599454\n",
            "geeks : 1.2876820724517808\n",
            "r2j : 1.6931471805599454\n",
            "\n",
            "Word indexes:\n",
            "{'geeks': 1, 'for': 0, 'r2j': 2}\n",
            "\n",
            "tf-idf value:\n",
            "  (0, 0)\t0.5493512310263033\n",
            "  (0, 1)\t0.8355915419449176\n",
            "  (1, 1)\t1.0\n",
            "  (2, 2)\t1.0\n",
            "\n",
            "tf-idf values in matrix form:\n",
            "[[0.54935123 0.83559154 0.        ]\n",
            " [0.         1.         0.        ]\n",
            " [0.         0.         1.        ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    }
  ]
}